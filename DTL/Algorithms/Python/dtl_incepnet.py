# -*- coding: utf-8 -*-
"""DTL-IncepNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hz3S9R0Rycj7UAssW8fYJBCJ7cN_fuGm

## Deep Transfer Learning with INCEPTION Network on DNA Sequence Dataset

By: Sk. Tanzir Mehedi

Importing libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import time
import sklearn
import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow.keras as keras
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.callbacks import TensorBoard
import warnings
# %matplotlib inline
warnings.filterwarnings('ignore')

"""Importing the Dataset"""

dataset=pd.read_csv('preprocessedDNASequenceDatase.csv')

"""Exploratory Data Analysis"""

dataset.head()

properties = list(dataset.columns.values)
properties.remove('label')
X = dataset[properties]
y = dataset['label']

"""Split Dataset into Training Set and Test Set"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

"""Check the nb classes"""

nb_classes = len(np.unique(np.concatenate((y_train, y_test), axis=0)))
nb_classes

"""Transform the labels from integers to one hot vectors"""

enc = sklearn.preprocessing.OneHotEncoder(categories='auto')
enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))

y_train = enc.transform(y_train.values.reshape(-1, 1)).toarray()
y_test = enc.transform(y_test.values.reshape(-1, 1)).toarray()

"""Save orignal y because later we will use binary"""

y_true = np.argmax(y_test, axis=1)

"""If univariate then add a dimension to make it multivariate with one dimension"""

if len(X_train.shape) == 2: 
        X_train = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))
        X_test = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))
        input_shape = X_train.shape[1:]

"""Making the Model"""

nb_filters=32
bottleneck_size = 32
stride=1
activation='linear'
kernel_size=41
use_residual=True
use_bottleneck=True

input_layer = keras.layers.Input(input_shape)
input_tensor = input_layer

x=input_layer

if use_bottleneck and int(input_tensor.shape[-1]) > bottleneck_size:
    input_inception = keras.layers.Conv1D(filters=bottleneck_size, kernel_size=1,padding='same', activation=activation, use_bias=False)(input_tensor)

else:
    input_inception = input_tensor

    # kernel_size_s = [3, 5, 8, 11, 17]
    kernel_size_s = [kernel_size // (2 ** i) for i in range(3)]

    conv_list = []

    for i in range(len(kernel_size_s)):
        conv_list.append(keras.layers.Conv1D(filters=nb_filters, kernel_size=kernel_size_s[i],strides=stride, padding='same', activation=activation, use_bias=False)(input_inception))

    max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)

    conv_6 = keras.layers.Conv1D(filters=nb_filters, kernel_size=1, padding='same', activation=activation, use_bias=False)(max_pool_1)

    conv_list.append(conv_6)

    x = keras.layers.Concatenate(axis=2)(conv_list)
    x = keras.layers.BatchNormalization()(x)
    x = keras.layers.Activation(activation='relu')(x)

gap_layer = keras.layers.GlobalAveragePooling1D()(x)

output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)

model = keras.models.Model(inputs=input_layer, outputs=output_layer)

"""Compile the Model"""

model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy'])
model.summary()

"""Result View with TensorBoard"""

NAME = "INCEPTION on DNA Seeuence Dataset"
tensorboard = TensorBoard(log_dir="logs/{}".format(NAME), histogram_freq = 1, profile_batch = '500,520')

"""Fitting the model"""

# X_test and y_test are only used to monitor the test loss and NOT for training

mini_batch_size = 64
nb_epochs = 1000

start_time = time.time()
history=model.fit(X_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs, validation_data=(X_test, y_test), callbacks=[tensorboard])
duration = time.time() - start_time

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# Reload the TensorBoard notebook extension
# %reload_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --/iot_combined_analysis/logs/

"""Making Predictions"""

start_time = time.time()
y_pred = model.predict(X_test)
duration1 = time.time() - start_time

"""Convert the predicted from binary to integer"""

y_pred = np.argmax(y_pred, axis=1)

"""Evaluating the Algorithm"""

print(confusion_matrix(y_true,y_pred))
print(classification_report(y_true,y_pred))

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_true, y_pred))

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_true, y_pred, average='weighted',labels=np.unique(y_pred)))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_true, y_pred,average='weighted', labels=np.unique(y_pred)))

#Calculate F1 Score
print("F1 Score:",metrics.f1_score(y_true, y_pred, average='weighted', labels=np.unique(y_pred)))

#Calculate Mean Absolute Error
print("Mean Absolute Error:",metrics.mean_absolute_error(y_true, y_pred))

# kappa
print("Cohens kappa:", metrics.cohen_kappa_score(y_true, y_pred))

# ROC AUC
print("ROC AUC:", metrics.roc_auc_score(y_true, y_pred))

#Train time
print('Train Time(s): ',duration) 

#Test time
print('Test Time(s): ',duration1)

# list all data in history
print(history.history.keys())

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

keras.backend.clear_session()